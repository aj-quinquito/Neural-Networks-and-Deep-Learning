{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b3dbad-0745-4949-872f-d195c9955c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a47805-0df4-4bb3-80a3-3ad02fcde2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422163</td>\n",
       "      <td>2378.908</td>\n",
       "      <td>837.8484</td>\n",
       "      <td>645.6693</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>733.1539</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>424428</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>1.2976</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2370</td>\n",
       "      <td>2.9574</td>\n",
       "      <td>4.2287</td>\n",
       "      <td>-5.919126e+10</td>\n",
       "      <td>-50714214400</td>\n",
       "      <td>-39922372608</td>\n",
       "      <td>58.7255</td>\n",
       "      <td>54.9554</td>\n",
       "      <td>47.8400</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338136</td>\n",
       "      <td>2085.144</td>\n",
       "      <td>723.8198</td>\n",
       "      <td>595.2073</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>656.1464</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>339014</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>1.2161</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6228</td>\n",
       "      <td>2.6350</td>\n",
       "      <td>3.1704</td>\n",
       "      <td>-3.423307e+10</td>\n",
       "      <td>-37462601728</td>\n",
       "      <td>-31477794816</td>\n",
       "      <td>50.0259</td>\n",
       "      <td>52.8168</td>\n",
       "      <td>47.8315</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526843</td>\n",
       "      <td>2647.394</td>\n",
       "      <td>940.7379</td>\n",
       "      <td>715.3638</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>819.0222</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>528876</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>1.3150</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7516</td>\n",
       "      <td>3.8611</td>\n",
       "      <td>4.7192</td>\n",
       "      <td>-9.394835e+10</td>\n",
       "      <td>-74738221056</td>\n",
       "      <td>-60311207936</td>\n",
       "      <td>65.4772</td>\n",
       "      <td>59.2860</td>\n",
       "      <td>51.9378</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416063</td>\n",
       "      <td>2351.210</td>\n",
       "      <td>827.9804</td>\n",
       "      <td>645.2988</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>727.8378</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>418255</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>1.2831</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0401</td>\n",
       "      <td>8.6136</td>\n",
       "      <td>8.2618</td>\n",
       "      <td>-3.207431e+10</td>\n",
       "      <td>-32060925952</td>\n",
       "      <td>-29575010304</td>\n",
       "      <td>43.3900</td>\n",
       "      <td>44.1259</td>\n",
       "      <td>41.1882</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347562</td>\n",
       "      <td>2160.354</td>\n",
       "      <td>763.9877</td>\n",
       "      <td>582.8359</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>665.2291</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>350797</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>1.3108</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7016</td>\n",
       "      <td>2.9761</td>\n",
       "      <td>4.4146</td>\n",
       "      <td>-3.998097e+10</td>\n",
       "      <td>-35980042240</td>\n",
       "      <td>-25593278464</td>\n",
       "      <td>52.7743</td>\n",
       "      <td>50.9080</td>\n",
       "      <td>42.6666</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n",
       "1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n",
       "2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n",
       "3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n",
       "4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n",
       "\n",
       "   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
       "0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n",
       "1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n",
       "2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n",
       "3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n",
       "4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n",
       "\n",
       "   KurtosisRB     EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n",
       "0      4.2287 -5.919126e+10 -50714214400 -39922372608     58.7255     54.9554   \n",
       "1      3.1704 -3.423307e+10 -37462601728 -31477794816     50.0259     52.8168   \n",
       "2      4.7192 -9.394835e+10 -74738221056 -60311207936     65.4772     59.2860   \n",
       "3      8.2618 -3.207431e+10 -32060925952 -29575010304     43.3900     44.1259   \n",
       "4      4.4146 -3.998097e+10 -35980042240 -25593278464     52.7743     50.9080   \n",
       "\n",
       "   ALLdaub4RB  Class  \n",
       "0     47.8400  BERHI  \n",
       "1     47.8315  BERHI  \n",
       "2     51.9378  BERHI  \n",
       "3     41.1882  BERHI  \n",
       "4     42.6666  BERHI  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Date_Fruit_Datasets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f7e754-d580-40b8-87b7-ea81275dd74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>SkewRB</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>298295.207127</td>\n",
       "      <td>2057.660953</td>\n",
       "      <td>750.811994</td>\n",
       "      <td>495.872785</td>\n",
       "      <td>0.737468</td>\n",
       "      <td>604.577938</td>\n",
       "      <td>0.981840</td>\n",
       "      <td>303845.592428</td>\n",
       "      <td>0.736267</td>\n",
       "      <td>2.131102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250518</td>\n",
       "      <td>4.247845</td>\n",
       "      <td>5.110894</td>\n",
       "      <td>3.780928</td>\n",
       "      <td>-3.185021e+10</td>\n",
       "      <td>-2.901860e+10</td>\n",
       "      <td>-2.771876e+10</td>\n",
       "      <td>50.082888</td>\n",
       "      <td>48.805681</td>\n",
       "      <td>48.098393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>107245.205337</td>\n",
       "      <td>410.012459</td>\n",
       "      <td>144.059326</td>\n",
       "      <td>114.268917</td>\n",
       "      <td>0.088727</td>\n",
       "      <td>119.593888</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>108815.656947</td>\n",
       "      <td>0.053745</td>\n",
       "      <td>17.820778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632918</td>\n",
       "      <td>2.892357</td>\n",
       "      <td>3.745463</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>2.037241e+10</td>\n",
       "      <td>1.712952e+10</td>\n",
       "      <td>1.484137e+10</td>\n",
       "      <td>16.063125</td>\n",
       "      <td>14.125911</td>\n",
       "      <td>10.813862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987.000000</td>\n",
       "      <td>911.828000</td>\n",
       "      <td>336.722700</td>\n",
       "      <td>2.283200</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>50.298400</td>\n",
       "      <td>0.836600</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>1.065300</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029100</td>\n",
       "      <td>1.708200</td>\n",
       "      <td>1.607600</td>\n",
       "      <td>1.767200</td>\n",
       "      <td>-1.091220e+11</td>\n",
       "      <td>-9.261697e+10</td>\n",
       "      <td>-8.747177e+10</td>\n",
       "      <td>15.191100</td>\n",
       "      <td>20.524700</td>\n",
       "      <td>22.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>206948.000000</td>\n",
       "      <td>1726.091500</td>\n",
       "      <td>641.068650</td>\n",
       "      <td>404.684375</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>513.317075</td>\n",
       "      <td>0.978825</td>\n",
       "      <td>210022.750000</td>\n",
       "      <td>0.705875</td>\n",
       "      <td>1.373725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>2.536625</td>\n",
       "      <td>2.508850</td>\n",
       "      <td>2.577275</td>\n",
       "      <td>-4.429444e+10</td>\n",
       "      <td>-3.894638e+10</td>\n",
       "      <td>-3.564534e+10</td>\n",
       "      <td>38.224425</td>\n",
       "      <td>38.654525</td>\n",
       "      <td>39.250725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>319833.000000</td>\n",
       "      <td>2196.345450</td>\n",
       "      <td>791.363400</td>\n",
       "      <td>495.054850</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>638.140950</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>327207.000000</td>\n",
       "      <td>0.746950</td>\n",
       "      <td>1.524150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135550</td>\n",
       "      <td>3.069800</td>\n",
       "      <td>3.127800</td>\n",
       "      <td>3.080700</td>\n",
       "      <td>-2.826156e+10</td>\n",
       "      <td>-2.620990e+10</td>\n",
       "      <td>-2.392928e+10</td>\n",
       "      <td>53.841300</td>\n",
       "      <td>50.337800</td>\n",
       "      <td>49.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>382573.000000</td>\n",
       "      <td>2389.716575</td>\n",
       "      <td>858.633750</td>\n",
       "      <td>589.031700</td>\n",
       "      <td>0.802150</td>\n",
       "      <td>697.930525</td>\n",
       "      <td>0.991800</td>\n",
       "      <td>388804.000000</td>\n",
       "      <td>0.775850</td>\n",
       "      <td>1.674750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593950</td>\n",
       "      <td>4.449850</td>\n",
       "      <td>7.320400</td>\n",
       "      <td>4.283125</td>\n",
       "      <td>-1.460482e+10</td>\n",
       "      <td>-1.433105e+10</td>\n",
       "      <td>-1.660367e+10</td>\n",
       "      <td>63.063350</td>\n",
       "      <td>59.573600</td>\n",
       "      <td>56.666675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>546063.000000</td>\n",
       "      <td>2811.997100</td>\n",
       "      <td>1222.723000</td>\n",
       "      <td>766.453600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>833.827900</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>552598.000000</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>535.525700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.092300</td>\n",
       "      <td>26.171100</td>\n",
       "      <td>26.736700</td>\n",
       "      <td>32.249500</td>\n",
       "      <td>-1.627316e+08</td>\n",
       "      <td>-5.627727e+08</td>\n",
       "      <td>-4.370435e+08</td>\n",
       "      <td>79.828900</td>\n",
       "      <td>83.064900</td>\n",
       "      <td>74.104600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AREA    PERIMETER   MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY  \\\n",
       "count     898.000000   898.000000   898.000000  898.000000    898.000000   \n",
       "mean   298295.207127  2057.660953   750.811994  495.872785      0.737468   \n",
       "std    107245.205337   410.012459   144.059326  114.268917      0.088727   \n",
       "min      1987.000000   911.828000   336.722700    2.283200      0.344800   \n",
       "25%    206948.000000  1726.091500   641.068650  404.684375      0.685625   \n",
       "50%    319833.000000  2196.345450   791.363400  495.054850      0.754700   \n",
       "75%    382573.000000  2389.716575   858.633750  589.031700      0.802150   \n",
       "max    546063.000000  2811.997100  1222.723000  766.453600      1.000000   \n",
       "\n",
       "          EQDIASQ    SOLIDITY    CONVEX_AREA      EXTENT  ASPECT_RATIO  ...  \\\n",
       "count  898.000000  898.000000     898.000000  898.000000    898.000000  ...   \n",
       "mean   604.577938    0.981840  303845.592428    0.736267      2.131102  ...   \n",
       "std    119.593888    0.018157  108815.656947    0.053745     17.820778  ...   \n",
       "min     50.298400    0.836600    2257.000000    0.512300      1.065300  ...   \n",
       "25%    513.317075    0.978825  210022.750000    0.705875      1.373725  ...   \n",
       "50%    638.140950    0.987300  327207.000000    0.746950      1.524150  ...   \n",
       "75%    697.930525    0.991800  388804.000000    0.775850      1.674750  ...   \n",
       "max    833.827900    0.997400  552598.000000    0.856200    535.525700  ...   \n",
       "\n",
       "           SkewRB  KurtosisRR  KurtosisRG  KurtosisRB     EntropyRR  \\\n",
       "count  898.000000  898.000000  898.000000  898.000000  8.980000e+02   \n",
       "mean     0.250518    4.247845    5.110894    3.780928 -3.185021e+10   \n",
       "std      0.632918    2.892357    3.745463    2.049831  2.037241e+10   \n",
       "min     -1.029100    1.708200    1.607600    1.767200 -1.091220e+11   \n",
       "25%     -0.196950    2.536625    2.508850    2.577275 -4.429444e+10   \n",
       "50%      0.135550    3.069800    3.127800    3.080700 -2.826156e+10   \n",
       "75%      0.593950    4.449850    7.320400    4.283125 -1.460482e+10   \n",
       "max      3.092300   26.171100   26.736700   32.249500 -1.627316e+08   \n",
       "\n",
       "          EntropyRG     EntropyRB  ALLdaub4RR  ALLdaub4RG  ALLdaub4RB  \n",
       "count  8.980000e+02  8.980000e+02  898.000000  898.000000  898.000000  \n",
       "mean  -2.901860e+10 -2.771876e+10   50.082888   48.805681   48.098393  \n",
       "std    1.712952e+10  1.484137e+10   16.063125   14.125911   10.813862  \n",
       "min   -9.261697e+10 -8.747177e+10   15.191100   20.524700   22.130000  \n",
       "25%   -3.894638e+10 -3.564534e+10   38.224425   38.654525   39.250725  \n",
       "50%   -2.620990e+10 -2.392928e+10   53.841300   50.337800   49.614100  \n",
       "75%   -1.433105e+10 -1.660367e+10   63.063350   59.573600   56.666675  \n",
       "max   -5.627727e+08 -4.370435e+08   79.828900   83.064900   74.104600  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c74989-ab0d-4502-881a-2147a51b0115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AREA           898 non-null    int64  \n",
      " 1   PERIMETER      898 non-null    float64\n",
      " 2   MAJOR_AXIS     898 non-null    float64\n",
      " 3   MINOR_AXIS     898 non-null    float64\n",
      " 4   ECCENTRICITY   898 non-null    float64\n",
      " 5   EQDIASQ        898 non-null    float64\n",
      " 6   SOLIDITY       898 non-null    float64\n",
      " 7   CONVEX_AREA    898 non-null    int64  \n",
      " 8   EXTENT         898 non-null    float64\n",
      " 9   ASPECT_RATIO   898 non-null    float64\n",
      " 10  ROUNDNESS      898 non-null    float64\n",
      " 11  COMPACTNESS    898 non-null    float64\n",
      " 12  SHAPEFACTOR_1  898 non-null    float64\n",
      " 13  SHAPEFACTOR_2  898 non-null    float64\n",
      " 14  SHAPEFACTOR_3  898 non-null    float64\n",
      " 15  SHAPEFACTOR_4  898 non-null    float64\n",
      " 16  MeanRR         898 non-null    float64\n",
      " 17  MeanRG         898 non-null    float64\n",
      " 18  MeanRB         898 non-null    float64\n",
      " 19  StdDevRR       898 non-null    float64\n",
      " 20  StdDevRG       898 non-null    float64\n",
      " 21  StdDevRB       898 non-null    float64\n",
      " 22  SkewRR         898 non-null    float64\n",
      " 23  SkewRG         898 non-null    float64\n",
      " 24  SkewRB         898 non-null    float64\n",
      " 25  KurtosisRR     898 non-null    float64\n",
      " 26  KurtosisRG     898 non-null    float64\n",
      " 27  KurtosisRB     898 non-null    float64\n",
      " 28  EntropyRR      898 non-null    float64\n",
      " 29  EntropyRG      898 non-null    int64  \n",
      " 30  EntropyRB      898 non-null    int64  \n",
      " 31  ALLdaub4RR     898 non-null    float64\n",
      " 32  ALLdaub4RG     898 non-null    float64\n",
      " 33  ALLdaub4RB     898 non-null    float64\n",
      " 34  Class          898 non-null    object \n",
      "dtypes: float64(30), int64(4), object(1)\n",
      "memory usage: 245.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb5ac1f-03c0-4d8b-8150-c60ba34aff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Missing values per column:\n",
      "Series([], dtype: int64)\n",
      "There are no missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check and display the number of duplicate rows\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "# Display duplicate rows (if any)\n",
    "if num_duplicates > 0:\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(df[df.duplicated()])\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# If no missing values\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"There are no missing values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2edae9d7-5b3a-405f-8fa3-66af54ea4f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class', ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the number of elements in each category in the 'Class' column\n",
    "class_counts = df['Class'].value_counts().reset_index()\n",
    "class_counts.columns = ['Class', 'Count']\n",
    "\n",
    "sns.barplot(x='Class', y='Count', data=class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e90fe-af64-46df-bb8e-f509d28b6189",
   "metadata": {},
   "source": [
    "Use markdown to comment on how well balanced the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426b3aff-ab43-4fbb-83e5-f9d527e5e2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AREA           898 non-null    int64  \n",
      " 1   PERIMETER      898 non-null    float64\n",
      " 2   MAJOR_AXIS     898 non-null    float64\n",
      " 3   MINOR_AXIS     898 non-null    float64\n",
      " 4   ECCENTRICITY   898 non-null    float64\n",
      " 5   EQDIASQ        898 non-null    float64\n",
      " 6   SOLIDITY       898 non-null    float64\n",
      " 7   CONVEX_AREA    898 non-null    int64  \n",
      " 8   EXTENT         898 non-null    float64\n",
      " 9   ASPECT_RATIO   898 non-null    float64\n",
      " 10  ROUNDNESS      898 non-null    float64\n",
      " 11  COMPACTNESS    898 non-null    float64\n",
      " 12  SHAPEFACTOR_1  898 non-null    float64\n",
      " 13  SHAPEFACTOR_2  898 non-null    float64\n",
      " 14  SHAPEFACTOR_3  898 non-null    float64\n",
      " 15  SHAPEFACTOR_4  898 non-null    float64\n",
      " 16  MeanRR         898 non-null    float64\n",
      " 17  MeanRG         898 non-null    float64\n",
      " 18  MeanRB         898 non-null    float64\n",
      " 19  StdDevRR       898 non-null    float64\n",
      " 20  StdDevRG       898 non-null    float64\n",
      " 21  StdDevRB       898 non-null    float64\n",
      " 22  SkewRR         898 non-null    float64\n",
      " 23  SkewRG         898 non-null    float64\n",
      " 24  SkewRB         898 non-null    float64\n",
      " 25  KurtosisRR     898 non-null    float64\n",
      " 26  KurtosisRG     898 non-null    float64\n",
      " 27  KurtosisRB     898 non-null    float64\n",
      " 28  EntropyRR      898 non-null    float64\n",
      " 29  EntropyRG      898 non-null    int64  \n",
      " 30  EntropyRB      898 non-null    int64  \n",
      " 31  ALLdaub4RR     898 non-null    float64\n",
      " 32  ALLdaub4RG     898 non-null    float64\n",
      " 33  ALLdaub4RB     898 non-null    float64\n",
      " 34  Class          898 non-null    int32  \n",
      "dtypes: float64(30), int32(1), int64(4)\n",
      "memory usage: 242.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Move the labels into a separate DataFrame\n",
    "class_labels = df['Class']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Class' column\n",
    "class_labels_encoded = label_encoder.fit_transform(class_labels)\n",
    "\n",
    "# Update the original DataFrame with the encoded labels\n",
    "df['Class'] = class_labels_encoded\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788725da-13f1-4cd9-92ba-69b57b93be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels as a 2D array:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'Class_encoded' column and reshape it into a 2D array\n",
    "class_labels_2d = class_labels_encoded.reshape(-1, 1)\n",
    "\n",
    "# Display the 2D array\n",
    "print(\"Labels as a 2D array:\")\n",
    "print(class_labels_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b349a5a-5f4c-4c70-a7a5-db0c0ce72b06",
   "metadata": {},
   "source": [
    "Below is the mapping of labels to integer values:\r\n",
    "\r\n",
    "- **BERHI**: 0\r\n",
    "- **DEGLET**: 1\r\n",
    "- **DOKOL**: 2\r\n",
    "- **IRAQI**: 3\r\n",
    "- **ROTANA**: 4\r\n",
    "- **SAFAVI**: 5\r\n",
    "- **SOGAY**: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b73ced-43d3-4bee-99d9-858768409f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77227446, 0.77207865, 0.56560444, ..., 0.67351302, 0.55053709,\n",
       "        0.4946647 ],\n",
       "       [0.61783464, 0.61747978, 0.43690403, ..., 0.53892305, 0.51634149,\n",
       "        0.49450116],\n",
       "       [0.96467405, 0.9133745 , 0.6817325 , ..., 0.77796738, 0.61978216,\n",
       "        0.57350706],\n",
       "       ...,\n",
       "       [0.46380101, 0.53411457, 0.46362467, ..., 0.44774729, 0.32417389,\n",
       "        0.36261751],\n",
       "       [0.43554209, 0.52334284, 0.42881001, ..., 0.55750041, 0.40280492,\n",
       "        0.45206697],\n",
       "       [0.62823025, 0.72490601, 0.5497979 , ..., 0.4974535 , 0.29056351,\n",
       "        0.33754565]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ec4a92-e14c-40e4-ae26-dec1050a991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 538 samples\n",
      "Validation set size: 180 samples\n",
      "Testing set size: 180 samples\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training (60%), testing (20%), and validation (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc9de21-d99c-4181-b976-479fde79ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),  \n",
    "    layers.Dense(1000, activation='relu'),  \n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(len(label_encoder.classes_), activation='softmax')  # Output layer with units equal to number of classes\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77c8aaf-5add-4c98-b3af-23b65ceab17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1000)              35000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 120)               120120    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 847       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,967\n",
      "Trainable params: 155,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b27663-ded9-4262-88c2-6dbb9469a9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 3s 92ms/step - loss: 1.5200 - accuracy: 0.5372 - val_loss: 1.1886 - val_accuracy: 0.6278\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.9606 - accuracy: 0.6506 - val_loss: 0.8046 - val_accuracy: 0.6778\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.7134 - accuracy: 0.7342 - val_loss: 0.6487 - val_accuracy: 0.8278\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 0.5845 - accuracy: 0.7807 - val_loss: 0.5606 - val_accuracy: 0.8444\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.4980 - accuracy: 0.8141 - val_loss: 0.5404 - val_accuracy: 0.8611\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4466 - accuracy: 0.8401 - val_loss: 0.5142 - val_accuracy: 0.8444\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 0.4451 - accuracy: 0.8271 - val_loss: 0.4861 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.4201 - accuracy: 0.8234 - val_loss: 0.4479 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3879 - accuracy: 0.8532 - val_loss: 0.4421 - val_accuracy: 0.8556\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3630 - accuracy: 0.8792 - val_loss: 0.4845 - val_accuracy: 0.8444\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 0.3688 - accuracy: 0.8773 - val_loss: 0.4099 - val_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.3277 - accuracy: 0.8885 - val_loss: 0.4864 - val_accuracy: 0.8278\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3731 - accuracy: 0.8476 - val_loss: 0.4328 - val_accuracy: 0.8667\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.3493 - accuracy: 0.8680 - val_loss: 0.4150 - val_accuracy: 0.8722\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3247 - accuracy: 0.8717 - val_loss: 0.4118 - val_accuracy: 0.8667\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.3175 - accuracy: 0.8773 - val_loss: 0.3994 - val_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 0.3092 - accuracy: 0.8755 - val_loss: 0.4023 - val_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3078 - accuracy: 0.8866 - val_loss: 0.4032 - val_accuracy: 0.8944\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.2872 - accuracy: 0.9052 - val_loss: 0.3883 - val_accuracy: 0.8944\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 0.2846 - accuracy: 0.8866 - val_loss: 0.4683 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to one-hot encoded format\n",
    "y_train_model1 = to_categorical(y_train)\n",
    "y_val_model1 = to_categorical(y_val)\n",
    "y_test_model1 = to_categorical(y_test)\n",
    "\n",
    "# Train the model\n",
    "model1 = model.fit(\n",
    "    X_train, y_train_model1,\n",
    "    validation_data=(X_val, y_val_model1),\n",
    "    epochs=20,  # Adjust the number of epochs as needed\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c371ec12-d29d-4dec-9a7c-4c03dd45f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "17/17 [==============================] - 3s 165ms/step - loss: 0.2890 - accuracy: 0.8810 - val_loss: 0.3962 - val_accuracy: 0.8833\n",
      "Epoch 2/40\n",
      "17/17 [==============================] - 2s 94ms/step - loss: 0.2723 - accuracy: 0.8941 - val_loss: 0.4252 - val_accuracy: 0.8667\n",
      "Epoch 3/40\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2947 - accuracy: 0.8885 - val_loss: 0.3854 - val_accuracy: 0.9000\n",
      "Epoch 4/40\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.2665 - accuracy: 0.9015 - val_loss: 0.3722 - val_accuracy: 0.9111\n",
      "Epoch 5/40\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2702 - accuracy: 0.8922 - val_loss: 0.4334 - val_accuracy: 0.8611\n",
      "Epoch 6/40\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2761 - accuracy: 0.8941 - val_loss: 0.5384 - val_accuracy: 0.8389\n",
      "Epoch 7/40\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 0.2881 - accuracy: 0.8885 - val_loss: 0.4317 - val_accuracy: 0.8778\n",
      "Epoch 8/40\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 0.2550 - accuracy: 0.8959 - val_loss: 0.3811 - val_accuracy: 0.9056\n",
      "Epoch 9/40\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2432 - accuracy: 0.9145 - val_loss: 0.3901 - val_accuracy: 0.8944\n",
      "Epoch 10/40\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.2603 - accuracy: 0.8885 - val_loss: 0.4382 - val_accuracy: 0.8667\n",
      "Epoch 11/40\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 0.2520 - accuracy: 0.9033 - val_loss: 0.3981 - val_accuracy: 0.8833\n",
      "Epoch 12/40\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 0.2388 - accuracy: 0.9108 - val_loss: 0.3915 - val_accuracy: 0.8889\n",
      "Epoch 13/40\n",
      "17/17 [==============================] - 1s 90ms/step - loss: 0.2586 - accuracy: 0.8996 - val_loss: 0.4284 - val_accuracy: 0.8833\n",
      "Epoch 14/40\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.2439 - accuracy: 0.8903 - val_loss: 0.4143 - val_accuracy: 0.8944\n",
      "Epoch 15/40\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 0.2527 - accuracy: 0.9015 - val_loss: 0.4280 - val_accuracy: 0.8944\n",
      "Epoch 16/40\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 0.2641 - accuracy: 0.8848 - val_loss: 0.3910 - val_accuracy: 0.9000\n",
      "Epoch 17/40\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2365 - accuracy: 0.9071 - val_loss: 0.4003 - val_accuracy: 0.8889\n",
      "Epoch 18/40\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2402 - accuracy: 0.9089 - val_loss: 0.3647 - val_accuracy: 0.9056\n",
      "Epoch 19/40\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 0.2224 - accuracy: 0.9201 - val_loss: 0.3765 - val_accuracy: 0.9000\n",
      "Epoch 20/40\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.2256 - accuracy: 0.9238 - val_loss: 0.3769 - val_accuracy: 0.8833\n",
      "Epoch 21/40\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 0.2247 - accuracy: 0.9052 - val_loss: 0.4026 - val_accuracy: 0.9000\n",
      "Epoch 22/40\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.2432 - accuracy: 0.9071 - val_loss: 0.4093 - val_accuracy: 0.8778\n",
      "Epoch 23/40\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2471 - accuracy: 0.9071 - val_loss: 0.4823 - val_accuracy: 0.8611\n",
      "Epoch 24/40\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.2644 - accuracy: 0.9089 - val_loss: 0.3667 - val_accuracy: 0.9056\n",
      "Epoch 25/40\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2632 - accuracy: 0.8978 - val_loss: 0.3647 - val_accuracy: 0.9222\n",
      "Epoch 26/40\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 0.2177 - accuracy: 0.9126 - val_loss: 0.3641 - val_accuracy: 0.9056\n",
      "Epoch 27/40\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2113 - accuracy: 0.9219 - val_loss: 0.3510 - val_accuracy: 0.9111\n",
      "Epoch 28/40\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2248 - accuracy: 0.9182 - val_loss: 0.3948 - val_accuracy: 0.9000\n",
      "Epoch 29/40\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 0.2266 - accuracy: 0.9219 - val_loss: 0.3629 - val_accuracy: 0.9111\n",
      "Epoch 30/40\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2241 - accuracy: 0.9182 - val_loss: 0.3946 - val_accuracy: 0.8944\n",
      "Epoch 31/40\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2233 - accuracy: 0.9089 - val_loss: 0.4169 - val_accuracy: 0.8944\n",
      "Epoch 32/40\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.2426 - accuracy: 0.9219 - val_loss: 0.3839 - val_accuracy: 0.8944\n",
      "Epoch 33/40\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1976 - accuracy: 0.9349 - val_loss: 0.3675 - val_accuracy: 0.9000\n",
      "Epoch 34/40\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2015 - accuracy: 0.9201 - val_loss: 0.4056 - val_accuracy: 0.8889\n",
      "Epoch 35/40\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2285 - accuracy: 0.9033 - val_loss: 0.3734 - val_accuracy: 0.9056\n",
      "Epoch 36/40\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2165 - accuracy: 0.9126 - val_loss: 0.3798 - val_accuracy: 0.9000\n",
      "Epoch 37/40\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2355 - accuracy: 0.9108 - val_loss: 0.4434 - val_accuracy: 0.8833\n",
      "Epoch 38/40\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2146 - accuracy: 0.9257 - val_loss: 0.3666 - val_accuracy: 0.9111\n",
      "Epoch 39/40\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1971 - accuracy: 0.9349 - val_loss: 0.4099 - val_accuracy: 0.8833\n",
      "Epoch 40/40\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2046 - accuracy: 0.9145 - val_loss: 0.4386 - val_accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to one-hot encoded format\n",
    "y_train_model2 = to_categorical(y_train)\n",
    "y_val_model2 = to_categorical(y_val)\n",
    "y_test_model2 = to_categorical(y_test)\n",
    "\n",
    "# Train the model\n",
    "model2 = model.fit(\n",
    "    X_train, y_train_model2,\n",
    "    validation_data=(X_val, y_val_model2),\n",
    "    epochs=40,  # Adjust the number of epochs as needed\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e77e540-fc77-48cc-a376-ffaa41b426f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.8778\n",
      "Validation accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val, y_val_model1)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caa7c706-d2f1-481d-96f1-c334c9c88651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8778\n",
      "Validation accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val, y_val_model2)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195ad5be-3b7f-4f8c-a634-91e833d8b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n",
      "Confusion Matrix:\n",
      "[[16  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  1  0  1]\n",
      " [ 0  5 37  0  0  0  0]\n",
      " [ 0  0  0 14  2  0  0]\n",
      " [ 0  0  0  0 36  0  0]\n",
      " [ 0  0  0  0  0 32  0]\n",
      " [ 0  5  0  0  2  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Predict classes on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Get predicted class indices\n",
    "\n",
    "# Convert test labels to their original form\n",
    "y_test_original = y_test.values\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_original, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7e785-db40-4e3c-9ac7-37507799c705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
